{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0005081-9584-4c0a-b9a3-a9805579b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f5a1e3-1230-40a2-8d3e-e327d12f59ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (4006193160.py, line -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line -1\u001b[0;36m\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "class Detector:\n",
    "    def __init__(self, model, options):\n",
    "        # self.data_dir = options[\"data_dir\"]\n",
    "        self.device = options[\"device\"]\n",
    "        self.model = model\n",
    "        self.model_path = options[\"model_path\"]\n",
    "        self.window_size = options[\"window_size\"]\n",
    "        self.num_candidates = options[\"num_candidates\"]\n",
    "        self.num_classes = options[\"num_classes\"]\n",
    "        self.input_size = options[\"input_size\"]\n",
    "        # self.sequentials = options[\"sequentials\"]\n",
    "        # self.quantitatives = options[\"quantitatives\"]\n",
    "        # self.semantics = options[\"semantics\"]\n",
    "        # self.batch_size = options[\"batch_size\"]\n",
    "\n",
    "    def detect_anomaly(self):\n",
    "        model = self.model.to(self.device)\n",
    "        model.load_state_dict(torch.load(self.model_path)[\"state_dict\"])\n",
    "        model.eval()\n",
    "        print(\"model_path: {}\".format(self.model_path))\n",
    "        test_normal_loader, test_normal_length = generate(\"hdfs_test_normal\")\n",
    "        test_abnormal_loader, test_abnormal_length = generate(\"hdfs_test_abnormal\")\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        # Test the model\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            # for line in tqdm(test_normal_loader.keys()):\n",
    "            # for i in range(len(line) - self.window_size):\n",
    "            # this code is persofmed in heach sequnce recived based on the the lenght of sequnce provided\n",
    "            seq0 = line[\n",
    "                i : i + self.window_size\n",
    "            ]  # initi the sequnce from line, in our case should be recived directly as paramter\n",
    "            label = line[\n",
    "                i + self.window_size\n",
    "            ]  # label is the next event after the sequnce, it should be recived from the aminer\n",
    "            seq1 = [0] * 28  #\n",
    "            log_conuter = Counter(seq0)  #\n",
    "            for key in log_conuter:\n",
    "                seq1[key] = log_conuter[key]\n",
    "\n",
    "            seq0 = (\n",
    "                torch.tensor(seq0, dtype=torch.float)\n",
    "                .view(-1, self.window_size, self.input_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "            seq1 = (\n",
    "                torch.tensor(seq1, dtype=torch.float)\n",
    "                .view(-1, self.num_classes, self.input_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "            label = torch.tensor(label).view(-1).to(self.device)\n",
    "            output = model(features=[seq0, seq1], device=self.device)\n",
    "            predicted = torch.argsort(output, 1)[0][-self.num_candidates :]\n",
    "            if label not in predicted:\n",
    "                FP += test_normal_loader[line]\n",
    "                break\n",
    "        \"\"\"with torch.no_grad():\n",
    "            for line in tqdm(test_abnormal_loader.keys()):\n",
    "                for i in range(len(line) - self.window_size):\n",
    "                    seq0 = line[i : i + self.window_size]\n",
    "                    label = line[i + self.window_size]\n",
    "                    seq1 = [0] * 28\n",
    "                    log_conuter = Counter(seq0)\n",
    "                    for key in log_conuter:\n",
    "                        seq1[key] = log_conuter[key]\n",
    "\n",
    "                    seq0 = (\n",
    "                        torch.tensor(seq0, dtype=torch.float)\n",
    "                        .view(-1, self.window_size, self.input_size)\n",
    "                        .to(self.device)\n",
    "                    )\n",
    "                    seq1 = (\n",
    "                        torch.tensor(seq1, dtype=torch.float)\n",
    "                        .view(-1, self.num_classes, self.input_size)\n",
    "                        .to(self.device)\n",
    "                    )\n",
    "                    label = torch.tensor(label).view(-1).to(self.device)\n",
    "                    output = model(features=[seq0, seq1], device=self.device)\n",
    "                    predicted = torch.argsort(output, 1)[0][-self.num_candidates :]\n",
    "                    if label not in predicted:\n",
    "                        TP += test_abnormal_loader[line]\n",
    "                        break\n",
    "\n",
    "        # Compute precision, recall and F1-measure\n",
    "        FN = test_abnormal_length - TP\n",
    "        P = 100 * TP / (TP + FP)\n",
    "        R = 100 * TP / (TP + FN)\n",
    "        F1 = 2 * P * R / (P + R)\n",
    "        print(\n",
    "            \"false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%\".format(\n",
    "                FP, FN, P, R, F1\n",
    "            )\n",
    "        )\n",
    "        print(\"Finished Predicting\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"elapsed_time: {}\".format(elapsed_time))\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
